{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI Chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrjVR9NFZAZP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "729a4a69-11f2-421f-d87a-01b971e2a855"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "stemmer= LancasterStemmer()\n",
        "\n",
        "import numpy \n",
        "import json\n",
        "import tensorflow \n",
        "import random \n",
        "import tflearn\n",
        "import pickle\n",
        "import zipfile\n",
        "from tensorflow import keras"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VRCl_kFvtEm",
        "outputId": "8b2da4da-60be-453d-8313-307727e2b945"
      },
      "source": [
        "!pip install tflearn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tflearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/3c/0b156d08ef3d4e2a8009ecab2af1ad2e304f6fb99562b6271c68a74a4397/tflearn-0.5.0.tar.gz (107kB)\n",
            "\r\u001b[K     |███                             | 10kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 20kB 20.2MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 30kB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 40kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 61kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 81kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 92kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 102kB 6.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tflearn) (7.0.0)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-cp37-none-any.whl size=127301 sha256=13304c81da712a238167224fbbdd7532f169f462bb70406d7fe8bd19b1142dea\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/d2/ed/fb9a0d301dd9586c11e9547120278e624227f22fd5f4baf744\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy-N_FuKlJXw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3177de59-dca0-4b40-933b-97580d8e02fd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0iFOtwY9cOf"
      },
      "source": [
        "zip_ref = zipfile.ZipFile(\"drive/My Drive/All Project Works/Software Engineering Project/ChatterBot.zip\", 'r')\r\n",
        "zip_ref.extractall(\"/content/\")\r\n",
        "zip_ref.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9o3eUDu-D6Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5382ec6-958f-42c8-d136-b9589ad2ceef"
      },
      "source": [
        "cd 'drive/My Drive/All Project Works/Software Engineering Project'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/All Project Works/Software Engineering Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRzNS5Afn3Q1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63b848dc-0622-4661-ed97-d82860d9097b"
      },
      "source": [
        "ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'AI Chatbot.ipynb'   data.pickle                     model.mdl.index\n",
            " Chatbot.py          intents.json                    model.mdl.meta\n",
            " ChatterBot.zip     \u001b[0m\u001b[01;34m'json file'\u001b[0m/\n",
            " checkpoint          model.mdl.data-00000-of-00001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NP1BDp2EZEEg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1db6a63-05b0-4bc3-8e3b-c2e6b989019d"
      },
      "source": [
        " file = \"intents.json\"\n",
        " \n",
        " with open(\"intents.json\") as file:\n",
        "    data=json.load(file)\n",
        "    \n",
        "print(data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'intents': [{'tag': 'greeting', 'patterns': ['Hi', 'How are you', 'Is anyone there?', 'Hello', 'Good day', 'Whats up'], 'responses': ['Hello!', 'Good to see you again!', 'Hi there, how can I help?'], 'context_set': ''}, {'tag': 'goodbye', 'patterns': ['cya', 'See you later', 'Goodbye', 'I am Leaving', 'Have a Good day'], 'responses': ['Sad to see you go :(', 'Talk to you later', 'Goodbye!'], 'context_set': ''}, {'tag': 'age', 'patterns': ['how old', 'how old is tim', 'what is your age', 'how old are you', 'age?'], 'responses': ['I am 18 years old!', '18 years young!'], 'context_set': ''}, {'tag': 'name', 'patterns': ['what is your name', 'what should I call you', 'whats your name?'], 'responses': ['You can call me Tim.', \"I'm Tim!\", \"I'm Tim aka Tech With Tim.\"], 'context_set': ''}, {'tag': 'shop', 'patterns': ['Id like to buy something', 'whats on the menu', 'what do you reccommend?', 'could i get something to eat'], 'responses': ['We sell chocolate chip cookies for $2!', 'Cookies are on the menu!'], 'context_set': ''}, {'tag': 'hours', 'patterns': ['when are you guys open', 'what are your hours', 'hours of operation'], 'responses': ['We are open 7am-4pm Monday-Friday!'], 'context_set': ''}]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag6cBxPJh3A8"
      },
      "source": [
        "try:\n",
        "  with open(\"data.pickle\",\"rb\") as f:\n",
        "    words, labels, training, output = pickle.load(f)\n",
        "except:\n",
        "  words = []\n",
        "  labels = []\n",
        "  docs_x = []\n",
        "  docs_y = []\n",
        "\n",
        "  for intent in data[\"intents\"]:\n",
        "      for pattern in intent[\"patterns\"]:\n",
        "          wrds = nltk.word_tokenize(pattern)\n",
        "          words.extend(wrds)\n",
        "          docs_x.append(wrds)\n",
        "          docs_y.append(intent[\"tag\"])\n",
        "          \n",
        "          if intent[\"tag\"] not in labels:\n",
        "              labels.append(intent[\"tag\"])\n",
        "\n",
        "  words = [stemmer.stem(w.lower()) for w in words if w not in \"?\"]\n",
        "  words = sorted(list(set(words)))\n",
        "\n",
        "  labels = sorted(labels)\n",
        "\n",
        "  training = []\n",
        "  output = []\n",
        "\n",
        "  out_empty=[0 for _ in range (len(labels))]\n",
        "\n",
        "  for x, doc in enumerate(docs_x):\n",
        "      bag = []\n",
        "\n",
        "      wrds = [stemmer.stem(w.lower()) for w in doc]\n",
        "      \n",
        "      for w in words:\n",
        "          if w in wrds:\n",
        "              bag.append(1)\n",
        "          else:\n",
        "              bag.append(0)\n",
        "      \n",
        "      \n",
        "      output_row = out_empty[:]\n",
        "      output_row[labels.index(docs_y[x])] = 1\n",
        "      \n",
        "      training.append(bag)\n",
        "      output.append(output_row)\n",
        "\n",
        "  \n",
        "    \n",
        "  training = numpy.array(training)\n",
        "  output = numpy.array(output)\n",
        "\n",
        "  with open(\"data.pickle\",\"wb\") as f:\n",
        "    pickle.dump((words, labels, training, output),f)\n",
        "\n",
        "tensorflow.compat.v1.reset_default_graph()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iv7W5oUVvKqS",
        "outputId": "42fb345c-8bb3-4d08-ba05-1ed8fa8a6ad1"
      },
      "source": [
        "len(output[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ERgjeKI-31G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "915b64a2-6ed6-4a51-953e-5a67fb54411d"
      },
      "source": [
        "net = tflearn.input_data(shape=[None, len(training[0])])\n",
        "net = tflearn.fully_connected(net,8)\n",
        "net = tflearn.fully_connected(net,8)\n",
        "net = tflearn.fully_connected(net,len(output[0]), activation=\"softmax\") \n",
        "net = tflearn.regression(net)\n",
        "\n",
        "model = tflearn.DNN(net)\n",
        "\n",
        "\n",
        "model.fit(training, output, n_epoch=1000, batch_size=8,show_metric=True)\n",
        "model.save(\"model.mdl\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 3999  | total loss: \u001b[1m\u001b[32m0.00992\u001b[0m\u001b[0m | time: 0.021s\n",
            "| Adam | epoch: 1000 | loss: 0.00992 - acc: 1.0000 -- iter: 24/26\n",
            "Training Step: 4000  | total loss: \u001b[1m\u001b[32m0.01016\u001b[0m\u001b[0m | time: 0.030s\n",
            "| Adam | epoch: 1000 | loss: 0.01016 - acc: 1.0000 -- iter: 26/26\n",
            "--\n",
            "INFO:tensorflow:/content/drive/My Drive/All Project Works/Software Engineering Project/model.mdl is not in all_model_checkpoint_paths. Manually adding it.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsX52Gkk9idm"
      },
      "source": [
        "def bag_of_words(sentence,words):\n",
        "  bag = [0 for _ in range(len(words))]\n",
        "\n",
        "  sentence_words = nltk.word_tokenize(sentence)\n",
        "  sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
        "\n",
        "  for se in sentence_words:\n",
        "    for i,w in enumerate(words):\n",
        "      if w == se:\n",
        "        bag[i] = 1\n",
        "\n",
        "  return numpy.array(bag)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9agEsv1nbn-",
        "outputId": "73cfbbc9-dac1-4895-a28f-d19e3f7a1d9a"
      },
      "source": [
        "model.load(\"model.mdl\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/All Project Works/Software Engineering Project/model.mdl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Plux_iMxLRV"
      },
      "source": [
        "def chat():\n",
        "  print(\"Start talking with the bot!\")\n",
        "\n",
        "  while True:\n",
        "\n",
        "    inp = input(\"You: \")\n",
        "\n",
        "    if inp.lower() == \"quit\":\n",
        "      break\n",
        "\n",
        "    results = model.predict([bag_of_words(inp,words)])\n",
        "\n",
        "    results_index = numpy.argmax(results)\n",
        "\n",
        "    tag = labels[results_index]\n",
        "\n",
        "    for tg in data[\"intents\"]:\n",
        "      if tg[\"tag\"] == tag:\n",
        "        responses = tg[\"responses\"]\n",
        "\n",
        "    print(random.choice(responses))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1G6N6NV0Zt9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "841861ed-cd50-4364-80f9-2715c22c6f2b"
      },
      "source": [
        "chat()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start talking with the bot!\n",
            "You: Hello\n",
            "Good to see you again!\n",
            "You: quit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glilfuh80mI6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}